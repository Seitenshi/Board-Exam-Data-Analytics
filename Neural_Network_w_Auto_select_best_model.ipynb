{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBo6xosCHPyq35CCDbfToP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seitenshi/Board-Exam-Data-Analytics/blob/main/Neural_Network_w_Auto_select_best_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FHTonY1CWF9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the uploaded CSV file\n",
        "url = 'https://raw.githubusercontent.com/Seitenshi/Board-Exam-Data-Analytics/main/BED%20Test%20-%20Combined.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Data preprocessing\n",
        "df['Remarks'] = df['Remarks'].replace({'FAILED': 0, 'PASSED': 1})  # Convert string labels to integers\n",
        "df = df.dropna()  # Drop rows with missing values\n",
        "df = df.drop(['Subj01', 'Subj02', 'Subj03', 'Gen. Average'], axis=1)  # Drop unnecessary columns\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df.drop('Remarks', axis=1).values\n",
        "y = df['Remarks'].values\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=69)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=69)\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_val = torch.FloatTensor(X_val)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_val = torch.LongTensor(y_val)\n",
        "y_test = torch.LongTensor(y_test)\n"
      ],
      "metadata": {
        "id": "EDFo-c0XkKyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the improved model\n",
        "class ImprovedModel(nn.Module):\n",
        "    def __init__(self, input=8, hidden=164, output=2):\n",
        "        super(ImprovedModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, output)\n",
        "        self.dropout = nn.Dropout(0.2)  # Add dropout with 20% probability\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Apply dropout after activation\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "4u2Yc1AnkP_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the improved model\n",
        "improved_model = ImprovedModel()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(improved_model.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "8jg7ANnFkULY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with validation and early stopping\n",
        "epochs = 100\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "best_model_state = None\n",
        "for epoch in range(epochs):\n",
        "    improved_model.train()  # Set the model to training mode\n",
        "    optimizer.zero_grad()\n",
        "    outputs = improved_model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    improved_model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        val_outputs = improved_model(X_val)\n",
        "        val_loss = criterion(val_outputs, y_val)\n",
        "        val_losses.append(val_loss.item())\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = improved_model.state_dict()  # Save the best model weights\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "    # Early stopping based on validation loss\n",
        "    if len(val_losses) > 10 and all(val_losses[-1] > val_losses[-i] for i in range(2, 6)):\n",
        "        print(\"Early stopping...\")\n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "id": "h_7HhRI4kXyr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a021e2-f815-4f13-9182-393933d67eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 0.7828, Val Loss: 0.7548\n",
            "Epoch 11/100, Train Loss: 0.6846, Val Loss: 0.6735\n",
            "Epoch 21/100, Train Loss: 0.6929, Val Loss: 0.6655\n",
            "Epoch 31/100, Train Loss: 0.6959, Val Loss: 0.6405\n",
            "Epoch 41/100, Train Loss: 0.6718, Val Loss: 0.6279\n",
            "Epoch 51/100, Train Loss: 0.6674, Val Loss: 0.6171\n",
            "Epoch 61/100, Train Loss: 0.6732, Val Loss: 0.6097\n",
            "Epoch 71/100, Train Loss: 0.6558, Val Loss: 0.6034\n",
            "Epoch 81/100, Train Loss: 0.6450, Val Loss: 0.5987\n",
            "Epoch 91/100, Train Loss: 0.6422, Val Loss: 0.5953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model and evaluate on the test set\n",
        "improved_model.load_state_dict(best_model_state)\n",
        "improved_model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = improved_model(X_test)\n",
        "    _, predicted = torch.max(test_outputs, 1)\n",
        "    accuracy = (predicted == y_test).sum().item() / len(y_test) * 100\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "e0zhHkNWkbTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9cb0e1-0d37-4b3b-c1d8-8bcd26fb6ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 60.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if the model predicts properly\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(X_test):\n",
        "    y_val = improved_model.forward(data)\n",
        "\n",
        "    # Semi Predictions\n",
        "    print(f'{i+1}.) {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}')\n",
        "\n",
        "    # Checking if correct or not\n",
        "    if y_val.argmax().item() == y_test[i]:\n",
        "      correct +=1\n",
        "\n",
        "print(f'No of correct items: {correct}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Top2fNdOhWJ0",
        "outputId": "a87d77dd-8d11-43ea-e331-104591552c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.) tensor([-0.2792, -0.0290]) \t 0 \t 1\n",
            "2.) tensor([-0.8155,  0.3659]) \t 1 \t 1\n",
            "3.) tensor([-0.7810,  0.3203]) \t 1 \t 1\n",
            "4.) tensor([-0.7843,  0.5515]) \t 1 \t 1\n",
            "5.) tensor([-0.1881, -0.1351]) \t 1 \t 1\n",
            "6.) tensor([-0.2595, -0.1350]) \t 1 \t 1\n",
            "7.) tensor([-0.2510,  0.2369]) \t 0 \t 1\n",
            "8.) tensor([-0.4005,  0.0218]) \t 0 \t 1\n",
            "9.) tensor([-0.7497,  0.3626]) \t 1 \t 1\n",
            "10.) tensor([-0.7625,  0.4566]) \t 1 \t 1\n",
            "11.) tensor([-0.6945,  0.1966]) \t 1 \t 1\n",
            "12.) tensor([-0.2949,  0.0517]) \t 1 \t 1\n",
            "13.) tensor([-0.3029,  0.2100]) \t 1 \t 1\n",
            "14.) tensor([-0.5673,  0.1839]) \t 1 \t 1\n",
            "15.) tensor([-0.6601, -0.1145]) \t 1 \t 1\n",
            "16.) tensor([-0.1696, -0.4130]) \t 0 \t 0\n",
            "17.) tensor([-0.3059,  0.0016]) \t 1 \t 1\n",
            "18.) tensor([-0.3532, -0.0391]) \t 0 \t 1\n",
            "19.) tensor([ 0.0234, -0.2800]) \t 1 \t 0\n",
            "20.) tensor([ 0.0524, -0.0437]) \t 1 \t 0\n",
            "21.) tensor([-1.0128,  0.5475]) \t 1 \t 1\n",
            "22.) tensor([-0.1696, -0.4130]) \t 1 \t 0\n",
            "23.) tensor([-0.3894,  0.0899]) \t 0 \t 1\n",
            "24.) tensor([-0.4028,  0.0820]) \t 1 \t 1\n",
            "25.) tensor([-0.4278,  0.2119]) \t 1 \t 1\n",
            "26.) tensor([-0.2387,  0.0187]) \t 0 \t 1\n",
            "27.) tensor([-0.2737, -0.1568]) \t 0 \t 1\n",
            "28.) tensor([-0.7069,  0.3164]) \t 1 \t 1\n",
            "29.) tensor([-0.4647,  0.0811]) \t 0 \t 1\n",
            "30.) tensor([-0.2145,  0.0066]) \t 0 \t 1\n",
            "No of correct items: 18\n"
          ]
        }
      ]
    }
  ]
}